{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb3144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4254878",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw/meteorological_information.csv', index_col=0)\n",
    "PATH_FEATURES = '../data/interim/drought_data_features.csv'\n",
    "drought_data_features = pd.read_csv(PATH_FEATURES, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c1a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_for_row_data(df, date_col):\n",
    "    df['index'] = df[date_col].dt.date.astype('str') + '__' + df.CVE_CONCATENADA.astype('str')\n",
    "    df.set_index('index', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9142a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_index = drought_data_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f3aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit_municipal_data(municipal_data):\n",
    "    CVE_CONCATENADA = municipal_data.CVEGEO.values[0] \n",
    "    daily_information = pd.DataFrame(literal_eval(municipal_data.meteorological_information.values[0])['daily'])\n",
    "    daily_information['time'] = pd.to_datetime(daily_information['time'])\n",
    "    daily_information = daily_information[daily_information.time > pd.to_datetime('2003-01-01')]\n",
    "    daily_information['sunrise'] = pd.to_datetime(daily_information['sunrise'])\n",
    "    daily_information['sunset'] = pd.to_datetime(daily_information['sunset'])\n",
    "    daily_information['day_duration'] = (daily_information['sunset']-daily_information['sunrise']).dt.seconds\n",
    "    daily_information['temperature_range'] = daily_information['temperature_2m_max'] - daily_information['temperature_2m_min']  \n",
    "    daily_information['temperature_max_apparent_range'] = daily_information['temperature_2m_max'] - daily_information['apparent_temperature_max']  \n",
    "    daily_information['temperature_min_apparent_range'] = daily_information['temperature_2m_min'] - daily_information['apparent_temperature_min']  \n",
    "    daily_information['temperature_mean_apparent_range'] = daily_information['temperature_2m_mean'] - daily_information['apparent_temperature_mean'] \n",
    "    daily_information['CVE_CONCATENADA'] = CVE_CONCATENADA\n",
    "    daily_information.rename(columns={'time':'DATE'}, inplace=True)\n",
    "    daily_information['NEW_DATE'] = daily_information['DATE'] + datetime.timedelta(days=10)\n",
    "    daily_information.drop(['sunrise', 'sunset'], axis=1, inplace=True)\n",
    "    daily_information = create_index_for_row_data(daily_information, 'DATE')\n",
    "    ## Calculate rolling windows\n",
    "    days = 120\n",
    "    drop_cols = ['weathercode', 'CVE_CONCATENADA', 'DATE']\n",
    "    daily_information_rolling = daily_information.drop(drop_cols, axis=1).rolling(f'{days}D', on='NEW_DATE', min_periods=days, closed='left')\n",
    "    daily_information_rolling_info = {}\n",
    "    daily_information_rolling_info['mean'] = daily_information_rolling.mean()\n",
    "    daily_information_rolling_info['std'] = daily_information_rolling.std()\n",
    "    daily_information_rolling_info['max'] = daily_information_rolling.max()\n",
    "    daily_information_rolling_info['min'] = daily_information_rolling.min()\n",
    "    daily_information_rolling_info['median'] = daily_information_rolling.median()\n",
    "    daily_information_rolling_info['skew'] = daily_information_rolling.skew()\n",
    "    daily_information_rolling_info['kurt'] = daily_information_rolling.kurt()\n",
    "    daily_information_rolling_info['mean_vs_median'] = daily_information_rolling_info['mean'] - daily_information_rolling_info['median']\n",
    "    daily_information_rolling_info['range'] = daily_information_rolling_info['max'] - daily_information_rolling_info['min']\n",
    "    daily_information_rolling_dfs = []\n",
    "    for operation, data in daily_information_rolling_info.items():\n",
    "        rename_col_dict = {\n",
    "            col:f'{col}__last{days}_days_{operation}' \n",
    "            for col in data.drop('NEW_DATE', axis=1).columns}\n",
    "        data.rename(columns=rename_col_dict, inplace=True)\n",
    "        daily_information_rolling_dfs.append(data)\n",
    "    concatenated_daily_information_rolling_df = pd.concat(daily_information_rolling_dfs, axis=1)\n",
    "    return concatenated_daily_information_rolling_df[concatenated_daily_information_rolling_df.index.isin(check_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "municipal_data_list = [] \n",
    "for i, mun in enumerate(data.CVEGEO.unique()):\n",
    "    municipal_data = data[data.CVEGEO==mun]\n",
    "    exploited_municipal_data = exploit_municipal_data(municipal_data)\n",
    "    municipal_data_list.append(exploited_municipal_data)\n",
    "    if not i%100:\n",
    "        print(i)\n",
    "municipal_data_meteorological_features = pd.concat(municipal_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc8e21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipal_data_meteorological_features = municipal_data_meteorological_features.loc[:,~municipal_data_meteorological_features.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "119e33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipal_data_meteorological_features.drop('NEW_DATE', axis=1).to_csv('../data/interim/meteorological_data_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c6ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
