{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e69b449",
   "metadata": {},
   "source": [
    "Information was obtained from https://www.inegi.org.mx/app/biblioteca/ficha.html?upc=889463807469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d442f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.utils import create_index_for_row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a0c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file('../data/raw/00mun.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccab24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersections_as_list(geom, df):\n",
    "    \"\"\"Assumes that df has a geometry column that may or not intersect\"\"\"\n",
    "    CVE_CONCATENADA_list = df[geom.intersects(df.geometry)].CVE_CONCATENADA.to_list()\n",
    "    return CVE_CONCATENADA_list\n",
    "\n",
    "def prepare_data_for_graph(df):\n",
    "    df['CVE_CONCATENADA'] = df.CVEGEO.astype(int)\n",
    "    df['intersection_list'] = df.geometry.apply(get_intersections_as_list, df=df)\n",
    "    data_for_graph = df[['CVE_CONCATENADA', 'intersection_list']].copy()\n",
    "    data_for_graph = data_for_graph.explode('intersection_list')\n",
    "    return data_for_graph, df\n",
    "\n",
    "def create_network(df, from_val='CVE_CONCATENADA', to_val='intersection_list'):\n",
    "    G = nx.from_pandas_edgelist(df, from_val, to_val)\n",
    "    return G\n",
    "\n",
    "def get_neighbours_from_graph(data, graph, *neighbours_distance):\n",
    "    neighbour_columns = ['CVE_CONCATENADA']\n",
    "    for n in neighbours_distance:\n",
    "        n_col = f'neighbours__{n}'\n",
    "        calc_neighbours_func = lambda x: list(nx.descendants_at_distance(graph, x, n))\n",
    "        data[n_col] = data.CVE_CONCATENADA.apply(calc_neighbours_func)\n",
    "        neighbour_columns.append(n_col)\n",
    "    graph_data = data[neighbour_columns].set_index('CVE_CONCATENADA')\n",
    "    return graph_data\n",
    "\n",
    "def add_graph_features(data, G):\n",
    "    data['triangles'] = pd.Series(nx.triangles(G))\n",
    "    data['clustering'] = pd.Series(nx.clustering(G))\n",
    "    data['square_clustering'] = pd.Series(nx.square_clustering(G))\n",
    "    data['degree_centrality'] = pd.Series(nx.degree_centrality(G))\n",
    "    data['eigenvector_centrality'] = pd.Series(nx.eigenvector_centrality(G))\n",
    "    data['katz_centrality'] = pd.Series(nx.katz_centrality(G))\n",
    "    data['closeness_centrality'] = pd.Series(nx.closeness_centrality(G))\n",
    "    data['information_centrality'] = pd.Series(nx.information_centrality(G))\n",
    "    data['betweenness_centrality'] = pd.Series(nx.betweenness_centrality(G))\n",
    "    data['node_clique_number'] = pd.Series(nx.node_clique_number(G))\n",
    "    data['voterank'] = pd.Series(nx.voterank(G)).reset_index().set_index(0)['index']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b137479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_for_graph, data = prepare_data_for_graph(data)\n",
    "    municipal_network = create_network(data_for_graph, from_val='CVE_CONCATENADA', to_val='intersection_list')\n",
    "    graph_data = get_neighbours_from_graph(data, municipal_network, 1,2,3)\n",
    "    graph_data = add_graph_features(graph_data, municipal_network)\n",
    "    neighbour_data = graph_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af1cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features1 = pd.read_csv('../data/interim/drought_data_features.csv', index_col=0)\n",
    "\n",
    "features2 = pd.read_csv('../data/interim/meteorological_data_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bcdf302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparent_temperature_max__last120_days_mean</th>\n",
       "      <th>apparent_temperature_mean__last120_days_mean</th>\n",
       "      <th>apparent_temperature_min__last120_days_mean</th>\n",
       "      <th>day_duration__last120_days_mean</th>\n",
       "      <th>precipitation_hours__last120_days_mean</th>\n",
       "      <th>precipitation_sum__last120_days_mean</th>\n",
       "      <th>rain_sum__last120_days_mean</th>\n",
       "      <th>shortwave_radiation_sum__last120_days_mean</th>\n",
       "      <th>temperature_2m_max__last120_days_mean</th>\n",
       "      <th>temperature_2m_mean__last120_days_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>precipitation_sum__last120_days_range</th>\n",
       "      <th>rain_sum__last120_days_range</th>\n",
       "      <th>shortwave_radiation_sum__last120_days_range</th>\n",
       "      <th>temperature_2m_max__last120_days_range</th>\n",
       "      <th>temperature_2m_mean__last120_days_range</th>\n",
       "      <th>temperature_2m_min__last120_days_range</th>\n",
       "      <th>temperature_max_apparent_range__last120_days_range</th>\n",
       "      <th>temperature_mean_apparent_range__last120_days_range</th>\n",
       "      <th>temperature_min_apparent_range__last120_days_range</th>\n",
       "      <th>temperature_range__last120_days_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-28__1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-02-28__1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-28__1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-28__1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-28__1001</th>\n",
       "      <td>25.151667</td>\n",
       "      <td>17.163333</td>\n",
       "      <td>9.669167</td>\n",
       "      <td>44313.5</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.218333</td>\n",
       "      <td>0.218333</td>\n",
       "      <td>25.581333</td>\n",
       "      <td>28.180833</td>\n",
       "      <td>20.192500</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.18</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15__32058</th>\n",
       "      <td>20.593333</td>\n",
       "      <td>12.561667</td>\n",
       "      <td>5.319167</td>\n",
       "      <td>40331.0</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.165833</td>\n",
       "      <td>0.165833</td>\n",
       "      <td>19.997917</td>\n",
       "      <td>22.914167</td>\n",
       "      <td>15.026667</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.13</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28__32058</th>\n",
       "      <td>20.913333</td>\n",
       "      <td>12.617500</td>\n",
       "      <td>5.126667</td>\n",
       "      <td>40759.5</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>21.011917</td>\n",
       "      <td>23.364167</td>\n",
       "      <td>15.270000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>15.51</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28__32058</th>\n",
       "      <td>22.441667</td>\n",
       "      <td>13.785000</td>\n",
       "      <td>5.947500</td>\n",
       "      <td>42356.5</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>23.516333</td>\n",
       "      <td>24.883333</td>\n",
       "      <td>16.567500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>16.45</td>\n",
       "      <td>13.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-15__32058</th>\n",
       "      <td>23.633333</td>\n",
       "      <td>14.794167</td>\n",
       "      <td>6.805833</td>\n",
       "      <td>43444.5</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>25.094250</td>\n",
       "      <td>26.040000</td>\n",
       "      <td>17.608333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.28</td>\n",
       "      <td>11.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-28__32058</th>\n",
       "      <td>24.570000</td>\n",
       "      <td>15.629167</td>\n",
       "      <td>7.530833</td>\n",
       "      <td>44303.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>25.868000</td>\n",
       "      <td>26.761667</td>\n",
       "      <td>18.306667</td>\n",
       "      <td>...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>14.04</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878964 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   apparent_temperature_max__last120_days_mean  \\\n",
       "index                                                            \n",
       "2003-01-28__1001                                           NaN   \n",
       "2003-02-28__1001                                           NaN   \n",
       "2003-03-28__1001                                           NaN   \n",
       "2003-04-28__1001                                           NaN   \n",
       "2003-05-28__1001                                     25.151667   \n",
       "...                                                        ...   \n",
       "2023-03-15__32058                                    20.593333   \n",
       "2023-03-28__32058                                    20.913333   \n",
       "2023-04-28__32058                                    22.441667   \n",
       "2023-05-15__32058                                    23.633333   \n",
       "2023-05-28__32058                                    24.570000   \n",
       "\n",
       "                   apparent_temperature_mean__last120_days_mean  \\\n",
       "index                                                             \n",
       "2003-01-28__1001                                            NaN   \n",
       "2003-02-28__1001                                            NaN   \n",
       "2003-03-28__1001                                            NaN   \n",
       "2003-04-28__1001                                            NaN   \n",
       "2003-05-28__1001                                      17.163333   \n",
       "...                                                         ...   \n",
       "2023-03-15__32058                                     12.561667   \n",
       "2023-03-28__32058                                     12.617500   \n",
       "2023-04-28__32058                                     13.785000   \n",
       "2023-05-15__32058                                     14.794167   \n",
       "2023-05-28__32058                                     15.629167   \n",
       "\n",
       "                   apparent_temperature_min__last120_days_mean  \\\n",
       "index                                                            \n",
       "2003-01-28__1001                                           NaN   \n",
       "2003-02-28__1001                                           NaN   \n",
       "2003-03-28__1001                                           NaN   \n",
       "2003-04-28__1001                                           NaN   \n",
       "2003-05-28__1001                                      9.669167   \n",
       "...                                                        ...   \n",
       "2023-03-15__32058                                     5.319167   \n",
       "2023-03-28__32058                                     5.126667   \n",
       "2023-04-28__32058                                     5.947500   \n",
       "2023-05-15__32058                                     6.805833   \n",
       "2023-05-28__32058                                     7.530833   \n",
       "\n",
       "                   day_duration__last120_days_mean  \\\n",
       "index                                                \n",
       "2003-01-28__1001                               NaN   \n",
       "2003-02-28__1001                               NaN   \n",
       "2003-03-28__1001                               NaN   \n",
       "2003-04-28__1001                               NaN   \n",
       "2003-05-28__1001                           44313.5   \n",
       "...                                            ...   \n",
       "2023-03-15__32058                          40331.0   \n",
       "2023-03-28__32058                          40759.5   \n",
       "2023-04-28__32058                          42356.5   \n",
       "2023-05-15__32058                          43444.5   \n",
       "2023-05-28__32058                          44303.0   \n",
       "\n",
       "                   precipitation_hours__last120_days_mean  \\\n",
       "index                                                       \n",
       "2003-01-28__1001                                      NaN   \n",
       "2003-02-28__1001                                      NaN   \n",
       "2003-03-28__1001                                      NaN   \n",
       "2003-04-28__1001                                      NaN   \n",
       "2003-05-28__1001                                 0.308333   \n",
       "...                                                   ...   \n",
       "2023-03-15__32058                                0.508333   \n",
       "2023-03-28__32058                                0.083333   \n",
       "2023-04-28__32058                                0.116667   \n",
       "2023-05-15__32058                                0.116667   \n",
       "2023-05-28__32058                                0.350000   \n",
       "\n",
       "                   precipitation_sum__last120_days_mean  \\\n",
       "index                                                     \n",
       "2003-01-28__1001                                    NaN   \n",
       "2003-02-28__1001                                    NaN   \n",
       "2003-03-28__1001                                    NaN   \n",
       "2003-04-28__1001                                    NaN   \n",
       "2003-05-28__1001                               0.218333   \n",
       "...                                                 ...   \n",
       "2023-03-15__32058                              0.165833   \n",
       "2023-03-28__32058                              0.021667   \n",
       "2023-04-28__32058                              0.028333   \n",
       "2023-05-15__32058                              0.040000   \n",
       "2023-05-28__32058                              0.146667   \n",
       "\n",
       "                   rain_sum__last120_days_mean  \\\n",
       "index                                            \n",
       "2003-01-28__1001                           NaN   \n",
       "2003-02-28__1001                           NaN   \n",
       "2003-03-28__1001                           NaN   \n",
       "2003-04-28__1001                           NaN   \n",
       "2003-05-28__1001                      0.218333   \n",
       "...                                        ...   \n",
       "2023-03-15__32058                     0.165833   \n",
       "2023-03-28__32058                     0.021667   \n",
       "2023-04-28__32058                     0.028333   \n",
       "2023-05-15__32058                     0.040000   \n",
       "2023-05-28__32058                     0.146667   \n",
       "\n",
       "                   shortwave_radiation_sum__last120_days_mean  \\\n",
       "index                                                           \n",
       "2003-01-28__1001                                          NaN   \n",
       "2003-02-28__1001                                          NaN   \n",
       "2003-03-28__1001                                          NaN   \n",
       "2003-04-28__1001                                          NaN   \n",
       "2003-05-28__1001                                    25.581333   \n",
       "...                                                       ...   \n",
       "2023-03-15__32058                                   19.997917   \n",
       "2023-03-28__32058                                   21.011917   \n",
       "2023-04-28__32058                                   23.516333   \n",
       "2023-05-15__32058                                   25.094250   \n",
       "2023-05-28__32058                                   25.868000   \n",
       "\n",
       "                   temperature_2m_max__last120_days_mean  \\\n",
       "index                                                      \n",
       "2003-01-28__1001                                     NaN   \n",
       "2003-02-28__1001                                     NaN   \n",
       "2003-03-28__1001                                     NaN   \n",
       "2003-04-28__1001                                     NaN   \n",
       "2003-05-28__1001                               28.180833   \n",
       "...                                                  ...   \n",
       "2023-03-15__32058                              22.914167   \n",
       "2023-03-28__32058                              23.364167   \n",
       "2023-04-28__32058                              24.883333   \n",
       "2023-05-15__32058                              26.040000   \n",
       "2023-05-28__32058                              26.761667   \n",
       "\n",
       "                   temperature_2m_mean__last120_days_mean  ...  \\\n",
       "index                                                      ...   \n",
       "2003-01-28__1001                                      NaN  ...   \n",
       "2003-02-28__1001                                      NaN  ...   \n",
       "2003-03-28__1001                                      NaN  ...   \n",
       "2003-04-28__1001                                      NaN  ...   \n",
       "2003-05-28__1001                                20.192500  ...   \n",
       "...                                                   ...  ...   \n",
       "2023-03-15__32058                               15.026667  ...   \n",
       "2023-03-28__32058                               15.270000  ...   \n",
       "2023-04-28__32058                               16.567500  ...   \n",
       "2023-05-15__32058                               17.608333  ...   \n",
       "2023-05-28__32058                               18.306667  ...   \n",
       "\n",
       "                   precipitation_sum__last120_days_range  \\\n",
       "index                                                      \n",
       "2003-01-28__1001                                     NaN   \n",
       "2003-02-28__1001                                     NaN   \n",
       "2003-03-28__1001                                     NaN   \n",
       "2003-04-28__1001                                     NaN   \n",
       "2003-05-28__1001                                     8.0   \n",
       "...                                                  ...   \n",
       "2023-03-15__32058                                    7.0   \n",
       "2023-03-28__32058                                    2.1   \n",
       "2023-04-28__32058                                    2.1   \n",
       "2023-05-15__32058                                    2.1   \n",
       "2023-05-28__32058                                    9.2   \n",
       "\n",
       "                   rain_sum__last120_days_range  \\\n",
       "index                                             \n",
       "2003-01-28__1001                            NaN   \n",
       "2003-02-28__1001                            NaN   \n",
       "2003-03-28__1001                            NaN   \n",
       "2003-04-28__1001                            NaN   \n",
       "2003-05-28__1001                            8.0   \n",
       "...                                         ...   \n",
       "2023-03-15__32058                           7.0   \n",
       "2023-03-28__32058                           2.1   \n",
       "2023-04-28__32058                           2.1   \n",
       "2023-05-15__32058                           2.1   \n",
       "2023-05-28__32058                           9.2   \n",
       "\n",
       "                   shortwave_radiation_sum__last120_days_range  \\\n",
       "index                                                            \n",
       "2003-01-28__1001                                           NaN   \n",
       "2003-02-28__1001                                           NaN   \n",
       "2003-03-28__1001                                           NaN   \n",
       "2003-04-28__1001                                           NaN   \n",
       "2003-05-28__1001                                         20.18   \n",
       "...                                                        ...   \n",
       "2023-03-15__32058                                        15.13   \n",
       "2023-03-28__32058                                        15.51   \n",
       "2023-04-28__32058                                        16.45   \n",
       "2023-05-15__32058                                        12.28   \n",
       "2023-05-28__32058                                        14.04   \n",
       "\n",
       "                   temperature_2m_max__last120_days_range  \\\n",
       "index                                                       \n",
       "2003-01-28__1001                                      NaN   \n",
       "2003-02-28__1001                                      NaN   \n",
       "2003-03-28__1001                                      NaN   \n",
       "2003-04-28__1001                                      NaN   \n",
       "2003-05-28__1001                                     15.8   \n",
       "...                                                   ...   \n",
       "2023-03-15__32058                                    12.1   \n",
       "2023-03-28__32058                                    12.1   \n",
       "2023-04-28__32058                                    13.6   \n",
       "2023-05-15__32058                                    11.5   \n",
       "2023-05-28__32058                                    11.3   \n",
       "\n",
       "                   temperature_2m_mean__last120_days_range  \\\n",
       "index                                                        \n",
       "2003-01-28__1001                                       NaN   \n",
       "2003-02-28__1001                                       NaN   \n",
       "2003-03-28__1001                                       NaN   \n",
       "2003-04-28__1001                                       NaN   \n",
       "2003-05-28__1001                                      15.6   \n",
       "...                                                    ...   \n",
       "2023-03-15__32058                                      8.5   \n",
       "2023-03-28__32058                                      8.5   \n",
       "2023-04-28__32058                                     10.3   \n",
       "2023-05-15__32058                                     10.1   \n",
       "2023-05-28__32058                                      9.5   \n",
       "\n",
       "                   temperature_2m_min__last120_days_range  \\\n",
       "index                                                       \n",
       "2003-01-28__1001                                      NaN   \n",
       "2003-02-28__1001                                      NaN   \n",
       "2003-03-28__1001                                      NaN   \n",
       "2003-04-28__1001                                      NaN   \n",
       "2003-05-28__1001                                     15.1   \n",
       "...                                                   ...   \n",
       "2023-03-15__32058                                     8.0   \n",
       "2023-03-28__32058                                     7.7   \n",
       "2023-04-28__32058                                     9.1   \n",
       "2023-05-15__32058                                    10.0   \n",
       "2023-05-28__32058                                     9.4   \n",
       "\n",
       "                   temperature_max_apparent_range__last120_days_range  \\\n",
       "index                                                                   \n",
       "2003-01-28__1001                                                 NaN    \n",
       "2003-02-28__1001                                                 NaN    \n",
       "2003-03-28__1001                                                 NaN    \n",
       "2003-04-28__1001                                                 NaN    \n",
       "2003-05-28__1001                                                 8.2    \n",
       "...                                                              ...    \n",
       "2023-03-15__32058                                                5.2    \n",
       "2023-03-28__32058                                                4.0    \n",
       "2023-04-28__32058                                                5.3    \n",
       "2023-05-15__32058                                                4.9    \n",
       "2023-05-28__32058                                                4.9    \n",
       "\n",
       "                   temperature_mean_apparent_range__last120_days_range  \\\n",
       "index                                                                    \n",
       "2003-01-28__1001                                                 NaN     \n",
       "2003-02-28__1001                                                 NaN     \n",
       "2003-03-28__1001                                                 NaN     \n",
       "2003-04-28__1001                                                 NaN     \n",
       "2003-05-28__1001                                                 7.0     \n",
       "...                                                              ...     \n",
       "2023-03-15__32058                                                3.4     \n",
       "2023-03-28__32058                                                2.8     \n",
       "2023-04-28__32058                                                2.6     \n",
       "2023-05-15__32058                                                2.6     \n",
       "2023-05-28__32058                                                3.3     \n",
       "\n",
       "                   temperature_min_apparent_range__last120_days_range  \\\n",
       "index                                                                   \n",
       "2003-01-28__1001                                                 NaN    \n",
       "2003-02-28__1001                                                 NaN    \n",
       "2003-03-28__1001                                                 NaN    \n",
       "2003-04-28__1001                                                 NaN    \n",
       "2003-05-28__1001                                                 6.9    \n",
       "...                                                              ...    \n",
       "2023-03-15__32058                                                3.1    \n",
       "2023-03-28__32058                                                2.6    \n",
       "2023-04-28__32058                                                2.8    \n",
       "2023-05-15__32058                                                2.8    \n",
       "2023-05-28__32058                                                3.6    \n",
       "\n",
       "                   temperature_range__last120_days_range  \n",
       "index                                                     \n",
       "2003-01-28__1001                                     NaN  \n",
       "2003-02-28__1001                                     NaN  \n",
       "2003-03-28__1001                                     NaN  \n",
       "2003-04-28__1001                                     NaN  \n",
       "2003-05-28__1001                                    12.1  \n",
       "...                                                  ...  \n",
       "2023-03-15__32058                                   11.6  \n",
       "2023-03-28__32058                                   11.0  \n",
       "2023-04-28__32058                                   10.2  \n",
       "2023-05-15__32058                                    8.1  \n",
       "2023-05-28__32058                                    8.3  \n",
       "\n",
       "[878964 rows x 135 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f3743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = pd.concat([features1, features2], axis=1)\n",
    "features = pd.concat([features1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30e917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_data = pd.read_csv('../data/interim/drought_data.csv', index_col=0)\n",
    "#drought_data.NEW_DATE = pd.to_datetime(drought_data.NEW_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50044d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['CVE_CONCATENADA'] = drought_data['CVE_CONCATENADA']\n",
    "features['NEW_DATE'] = pd.to_datetime(drought_data['NEW_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212f222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_for_neighbour_features(row, data):\n",
    "    grouped_dfs = []\n",
    "    statistic_value_list = ['mean', 'std', 'min', 'max', 'median']\n",
    "    for neighbour_num in row.index:\n",
    "        if not 'neighbour' in neighbour_num:\n",
    "            continue\n",
    "        df_grouped = data[\n",
    "            data.CVE_CONCATENADA.isin(\n",
    "                row[neighbour_num]\n",
    "            )\n",
    "        ].drop('CVE_CONCATENADA',axis=1).groupby('NEW_DATE')\n",
    "        all_statistics_list = []\n",
    "        for statistic in statistic_value_list:\n",
    "            df_grouped_statistic = df_grouped.agg(statistic)\n",
    "            df_grouped_statistic.columns = [f'{col}__{neighbour_num}_{statistic}' for col in df_grouped_statistic.columns]\n",
    "            all_statistics_list.append(df_grouped_statistic)\n",
    "        all_statistics_df = pd.concat(all_statistics_list, axis=1)\n",
    "        all_statistics_df['CVE_CONCATENADA'] = row.name\n",
    "        all_statistics_df.reset_index(inplace=True)\n",
    "        grouped_dfs.append(all_statistics_df) \n",
    "    final_neighbour_features_result = pd.concat(grouped_dfs, axis=1)\n",
    "    final_neighbour_features_result = final_neighbour_features_result.loc[:,~final_neighbour_features_result.columns.duplicated()].copy()\n",
    "    return final_neighbour_features_result\n",
    "\n",
    "neighbour_features_series = neighbour_data.apply(function_for_neighbour_features, data=features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438de533",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_features = pd.concat(neighbour_features_series.to_list())\n",
    "neighbour_features.NEW_DATE = pd.to_datetime(neighbour_features.NEW_DATE)\n",
    "neighbour_features = create_index_for_row_data(neighbour_features, 'NEW_DATE')\n",
    "neighbour_features.drop(['NEW_DATE', 'CVE_CONCATENADA'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d376bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
      "/tmp/ipykernel_1961/1047589983.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_feature] = df[beta_feature]-df[alpha_feature]\n"
     ]
    }
   ],
   "source": [
    "def complement_neighbour_features(data, alpha=1, beta=2):\n",
    "    df = data.copy()\n",
    "    statistic_value_list = ['mean', 'std', 'min', 'max', 'median']\n",
    "    possible_candidates = list(set([col.rsplit('__',1)[0] for col in df.columns.to_list()]))\n",
    "    new_feature_list = []\n",
    "    for val in possible_candidates:\n",
    "        for stat in statistic_value_list:\n",
    "            new_feature = f'{val}__{beta}vs{alpha}_{stat}'\n",
    "            alpha_feature = f'{val}__{beta}_{stat}'\n",
    "            beta_feature = f'{val}__{alpha}_{stat}'\n",
    "            df[new_feature] = df[beta_feature]-df[alpha_feature]\n",
    "            new_feature_list.append(new_feature)\n",
    "    return df[new_feature_list]\n",
    "\n",
    "neighbour_features_12 = complement_neighbour_features(neighbour_features, 1, 2)\n",
    "neighbour_features_13 = complement_neighbour_features(neighbour_features, 1, 3)\n",
    "neighbour_features_23 = complement_neighbour_features(neighbour_features, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f5c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neighbour_features = pd.concat(\n",
    "    [neighbour_features,\n",
    "     neighbour_features_12,\n",
    "     neighbour_features_13,\n",
    "     neighbour_features_23\n",
    "    ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316e9b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neighbour_features.to_csv('../data/interim/drought_data_neighbour_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57b588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
