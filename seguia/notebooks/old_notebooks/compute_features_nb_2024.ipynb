{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e793d8",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad4b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd8302",
   "metadata": {},
   "source": [
    "# Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c7ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_path = \"../data/raw/muni.pkl\"\n",
    "geo_data = pd.read_pickle(geodata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ca2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "droughtdata_path = \"../data/raw/drought_data.parquet\"\n",
    "drought_data = pd.read_parquet(droughtdata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19bbe8a",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3181692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_for_row_data(df, date_col):\n",
    "    df['index'] = df[date_col].dt.date.astype('str') + '__' + df.CVE_CONCATENADA.astype('str')\n",
    "    df.set_index('index', inplace=True)\n",
    "    return df\n",
    "\n",
    "def create_column_for_merge(df, col1, col2):\n",
    "    df[f'{col1}_{col2}'] = df[col1].astype('str') + '__' + df[col2].astype('str')\n",
    "    return df\n",
    "\n",
    "def prepare_data_for_graph(df):\n",
    "    df['intersection_list'] = df.geometry.apply(get_intersections_as_list, df=df)\n",
    "    data_for_graph = df[['CVEGEO', 'intersection_list']].copy()\n",
    "    data_for_graph = data_for_graph.explode('intersection_list')\n",
    "    return data_for_graph, df\n",
    "\n",
    "def get_intersections_as_list(geom, df):\n",
    "    \"\"\"Assumes that df has a geometry column that may or not intersect\"\"\"\n",
    "    CVEGEO_list = df[geom.intersects(df.geometry)].CVEGEO.to_list()\n",
    "    return CVEGEO_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943eb77",
   "metadata": {},
   "source": [
    "# Data Proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25778969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drought index\n",
      "Target creation\n",
      "Index presence creation\n",
      "Creation of graph\n",
      "neighbour_calc\n"
     ]
    }
   ],
   "source": [
    "df = drought_data\n",
    "df.CVE_CONCATENADA = df.CVE_CONCATENADA.astype(str).apply(lambda x: x.zfill(5))\n",
    "\n",
    "id_columns = [col for col in df.columns if not('00:00:00' in col)]\n",
    "target = 'DROUGHT_INDEX'\n",
    "\n",
    "data = pd.melt(df, id_vars=id_columns, var_name='DATE', value_name=target)\n",
    "data.DATE = pd.to_datetime(data.DATE)\n",
    "data = data[data.DATE > pd.to_datetime(\"2016-01-01\")]\n",
    "\n",
    "data['day'] = data.DATE.apply(lambda x: x.day)\n",
    "half_month_condition = data.day > 15\n",
    "data.loc[half_month_condition, 'DATE'] = data.loc[half_month_condition].DATE.apply(lambda x: x.replace(day=28))\n",
    "data.drop('day', axis=1, inplace=True)\n",
    "\n",
    "print('Drought index')\n",
    "data.DROUGHT_INDEX = data.DROUGHT_INDEX.str.replace('D', '').astype('float').fillna(0)\n",
    "\n",
    "# Data for features\n",
    "\n",
    "data_for_features = create_column_for_merge(data, 'CLV_OC', 'DATE')\n",
    "data_for_features = create_index_for_row_data(data_for_features, 'DATE')\n",
    "\n",
    "operators = ['mean', 'min', 'max', 'median']\n",
    "clv_rename = {oper: f\"di_clv_oc_group__{oper}\" for oper in operators}\n",
    "\n",
    "clv_oc_date = data_for_features.groupby(['CLV_OC', 'DATE']).DROUGHT_INDEX.agg(operators).reset_index()\n",
    "clv_oc_date = create_column_for_merge(clv_oc_date, 'CLV_OC', 'DATE').drop(['CLV_OC', 'DATE'], axis=1).rename(columns=clv_rename)\n",
    "data_for_features = data_for_features.merge(clv_oc_date, on='CLV_OC_DATE', how='left').set_index(data.index)\n",
    "\n",
    "data_for_features['di_vs_group_di__mean'] = data_for_features['di_clv_oc_group__mean'] - data_for_features['DROUGHT_INDEX']\n",
    "data_for_features['di_vs_group_di__min'] = data_for_features['di_clv_oc_group__min'] - data_for_features['DROUGHT_INDEX']\n",
    "data_for_features['di_vs_group_di__max'] = data_for_features['di_clv_oc_group__max'] - data_for_features['DROUGHT_INDEX']\n",
    "data_for_features['di_vs_group_di__median'] = data_for_features['di_clv_oc_group__median'] - data_for_features['DROUGHT_INDEX']\n",
    "\n",
    "# Create target for 1, 3 and 6 months into the future. \n",
    "print('Target creation')\n",
    "for months in (1,3,6):\n",
    "    displaced_drought_data = data.copy()\n",
    "    column = f'DISPLACED_DATE__{months}MONTHS'\n",
    "    target_new =  f'DROUGHT_INDEX__NEXT_{months}MONTHS'\n",
    "    displaced_drought_data[column] = displaced_drought_data['DATE'].apply(lambda date: date + relativedelta(months=-months)) \n",
    "    temporary_df = create_index_for_row_data(displaced_drought_data, column)\n",
    "    temporary_df.rename(columns={'DROUGHT_INDEX': target_new}, inplace=True)\n",
    "    data_for_features[target_new] = temporary_df[target_new]\n",
    "    \n",
    "print('Index presence creation')\n",
    "data_for_features.loc[data[target]==0, 'is_0_index'] = 1\n",
    "data_for_features.loc[data[target]==1, 'is_1_index'] = 1\n",
    "data_for_features.loc[data[target]==2, 'is_2_index'] = 1\n",
    "data_for_features.loc[data[target]==3, 'is_3_index'] = 1\n",
    "data_for_features.loc[data[target]==4, 'is_4_index'] = 1\n",
    "\n",
    "data_for_features.is_0_index = data_for_features.is_0_index.fillna(0)\n",
    "data_for_features.is_1_index = data_for_features.is_1_index.fillna(0)\n",
    "data_for_features.is_2_index = data_for_features.is_2_index.fillna(0)\n",
    "data_for_features.is_3_index = data_for_features.is_3_index.fillna(0)\n",
    "data_for_features.is_4_index = data_for_features.is_4_index.fillna(0)\n",
    "\n",
    "############################################################################ NEEDS REFACTOR\n",
    "############################################################################ neighbour features\n",
    "\n",
    "print('Creation of graph')\n",
    "data_for_graph, reduced_data_with_intersection_list = prepare_data_for_graph(geo_data)\n",
    "\n",
    "helper_data = data[['CVE_CONCATENADA', 'DATE', 'DROUGHT_INDEX']]\n",
    "\n",
    "reduced_data_with_intersection_list = reduced_data_with_intersection_list[['CVEGEO', 'intersection_list']].rename(columns={\"CVEGEO\":\"CVE_CONCATENADA\"})\n",
    "# Esto es algo que siempre tendremos calculado (entonces hace falta guardarlo) : \n",
    "dict_neigh = reduced_data_with_intersection_list.set_index('CVE_CONCATENADA').intersection_list.to_dict()\n",
    "\n",
    "def helper_function(cve_concat):\n",
    "    operators = ['mean', 'min', 'max', 'median', 'std']\n",
    "    neighbours = helper_data[helper_data.CVE_CONCATENADA.isin(dict_neigh.get(cve_concat))]\n",
    "    neighbours = neighbours.groupby('DATE').DROUGHT_INDEX.agg(operators).reset_index()\n",
    "    neighbours['CVE_CONCATENADA'] = cve_concat\n",
    "    neighbours = create_index_for_row_data(neighbours, 'DATE')\n",
    "    neigh_rename = {oper: f\"di_neighbour_group__{oper}\" for oper in operators}\n",
    "    return  neighbours.drop(['DATE', 'CVE_CONCATENADA'], axis=1).rename(columns=neigh_rename)\n",
    "\n",
    "# Takes 42 seconds\n",
    "print('neighbour_calc')\n",
    "neighbour_di = pd.concat(reduced_data_with_intersection_list.CVE_CONCATENADA.apply(helper_function).to_list())\n",
    "\n",
    "\n",
    "for col in neighbour_di: \n",
    "    data_for_features[col] = neighbour_di[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d1e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save targets for data\n",
    "targets = data_for_features[['DROUGHT_INDEX__NEXT_1MONTHS', 'DROUGHT_INDEX__NEXT_3MONTHS', 'DROUGHT_INDEX__NEXT_6MONTHS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b6913",
   "metadata": {},
   "source": [
    "# Feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33993c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for DROUGHT_INDEX\n",
      "2.594438500003889\n",
      "Computing for di_vs_group_di__mean\n",
      "2.6906204998958856\n",
      "Computing for di_vs_group_di__min\n",
      "2.960608399938792\n",
      "Computing for di_vs_group_di__max\n",
      "3.060362200019881\n",
      "Computing for di_vs_group_di__median\n",
      "3.079937699949369\n",
      "Computing for di_neighbour_group__mean\n",
      "3.085919899865985\n",
      "Computing for di_neighbour_group__min\n",
      "3.059578299988061\n",
      "Computing for di_neighbour_group__max\n",
      "3.175798599841073\n",
      "Computing for di_neighbour_group__median\n",
      "3.1241186999250203\n",
      "Computing for di_neighbour_group__std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17521/1456604102.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_last180_days_same_cve__max'] = rolling_df_180D_by_cve[feature].max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.140877300174907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17521/1456604102.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_last180_days_same_cve__min'] = rolling_df_180D_by_cve[feature].min()\n",
      "/tmp/ipykernel_17521/1456604102.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_last180_days_same_cve__range'] = df[f'{feature}_last180_days_same_cve__max'] - df[f'{feature}_last180_days_same_cve__min']\n",
      "/tmp/ipykernel_17521/1456604102.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_last180_days_same_cve__central_diff'] = df[f'{feature}_last180_days_same_cve__mean'] - df[f'{feature}_last180_days_same_cve__median']\n",
      "/tmp/ipykernel_17521/1456604102.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_last180_days_same_cve__central_diff_range_proportion'] = features[f'{feature}_last180_days_same_cve__central_diff']/features[f'{feature}_last180_days_same_cve__range']\n"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame()\n",
    "\n",
    "rolling_df_180D_by_cve = data_for_features.groupby('CVE_CONCATENADA').rolling('180D', on='DATE', min_periods=10)\n",
    "\n",
    "for di_coef in (0,1,2,3,4):\n",
    "    features[f'proportion_is_{di_coef}_index_last180_days_same_cve'] = rolling_df_180D_by_cve[f'is_{di_coef}_index'].mean()\n",
    "\n",
    "# operation drought last 180 days same cve_concat\n",
    "def calculate_to_feature_df_last180_days_same_cve(df, feature):\n",
    "    print(f'Computing for {feature}')\n",
    "    t = time.perf_counter()\n",
    "    df[f'{feature}_last180_days_same_cve__mean'] = rolling_df_180D_by_cve[feature].mean()\n",
    "    df[f'{feature}_last180_days_same_cve__median'] = rolling_df_180D_by_cve[feature].median()\n",
    "    df[f'{feature}_last180_days_same_cve__std'] = rolling_df_180D_by_cve[feature].std()\n",
    "    df[f'{feature}_last180_days_same_cve__kurt'] = rolling_df_180D_by_cve[feature].kurt()\n",
    "    df[f'{feature}_last180_days_same_cve__skew'] = rolling_df_180D_by_cve[feature].skew()\n",
    "    df[f'{feature}_last180_days_same_cve__max'] = rolling_df_180D_by_cve[feature].max()\n",
    "    df[f'{feature}_last180_days_same_cve__min'] = rolling_df_180D_by_cve[feature].min()\n",
    "    df[f'{feature}_last180_days_same_cve__range'] = df[f'{feature}_last180_days_same_cve__max'] - df[f'{feature}_last180_days_same_cve__min']\n",
    "    df[f'{feature}_last180_days_same_cve__central_diff'] = df[f'{feature}_last180_days_same_cve__mean'] - df[f'{feature}_last180_days_same_cve__median']\n",
    "    df[f'{feature}_last180_days_same_cve__central_diff_range_proportion'] = features[f'{feature}_last180_days_same_cve__central_diff']/features[f'{feature}_last180_days_same_cve__range']\n",
    "    #df[f'{feature}_last180_days_same_cve__tendency'] = rolling_df_180D_by_cve[feature].apply(lambda x: (x[-1]-x[0])/len(x))\n",
    "    print(time.perf_counter()-t)\n",
    "\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'DROUGHT_INDEX')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_vs_group_di__mean')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_vs_group_di__min')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_vs_group_di__max')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_vs_group_di__median')\n",
    "\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_neighbour_group__mean')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_neighbour_group__min')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_neighbour_group__max')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_neighbour_group__median')\n",
    "calculate_to_feature_df_last180_days_same_cve(features, 'di_neighbour_group__std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d43c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_save = create_index_for_row_data(features.reset_index(), 'DATE').drop(['CVE_CONCATENADA', 'DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d1dd6",
   "metadata": {},
   "source": [
    "# Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff247d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_save.to_parquet('../data/interim/drought_data_features2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fd7e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.to_parquet('../data/interim/drought_data_targets2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ca9c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['CVE_CONCATENADA', 'DATE', 'DROUGHT_INDEX']].to_parquet('../data/interim/drought_data_info2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf92f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
